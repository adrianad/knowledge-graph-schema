# Example environment variables
# Copy this file to .env and update with your database credentials

# Database connection string (used as default for -c/--connection)
DATABASE_URL=postgresql://username:password@localhost:5432/database_name

# Alternative database examples:
# SQLite
# DATABASE_URL=sqlite:///path/to/your/database.db

# MySQL
# DATABASE_URL=mysql+pymysql://username:password@localhost:3306/database_name

# OpenAI-compatible API configuration for LLM keyword extraction
OPENAI_API_BASE=http://localhost:8000/v1
OPENAI_API_KEY=your_api_key_here
LLM_MODEL=qwen-model-name
LLM_MAX_CONCURRENT=10

# Neo4j configuration for keyword storage and semantic search
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# Main cluster configuration - number of top clusters to combine into main cluster
MAIN_CLUSTER_SIZE=2

# SQL execution configuration - maximum tokens before truncating results
SQL_MAX_TOKENS=10000

# SQL query timeout in milliseconds (default: 5000ms = 5 seconds)
SQL_STATEMENT_TIMEOUT_MS=5000

# Path finding configuration - maximum hops to explore when finding table connections
MAX_HOPS=3

# Example for different providers:
# For OpenAI:
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_API_KEY=sk-your-openai-key
# LLM_MODEL=gpt-3.5-turbo

# For Anthropic Claude (via OpenAI-compatible proxy):
# OPENAI_API_BASE=http://localhost:8080/v1
# OPENAI_API_KEY=your-anthropic-key
# LLM_MODEL=claude-3-haiku

# For local models via vLLM:
# OPENAI_API_BASE=http://localhost:8000/v1
# OPENAI_API_KEY=dummy-key
# LLM_MODEL=your-local-model-name